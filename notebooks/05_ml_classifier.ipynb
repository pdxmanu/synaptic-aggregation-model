{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c949a61-62f5-4dbe-9257-3f6d6e91cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 05_ml_analysis.ipynb (single-cell)\n",
    "# Machine Learning on synaptic signal degradation patterns (alpha-synuclein aggregation)\n",
    "# This cell is self-contained and does NOT modify your 03_* notebook.\n",
    "\n",
    "from brian2 import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# Setup\n",
    "# -----------------------------\n",
    "# Inline plotting for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Folders\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Deterministic run and smooth integration for clock-driven dynamics\n",
    "np.random.seed(42)\n",
    "defaultclock.dt = 0.1*ms\n",
    "\n",
    "# Optional: silence Brian2 \"internal variable will be used\" warnings (best fix is variable renaming below)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*internal variable of group 'neurongroup_.*' .* also exists in the run namespace.*\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Simulation helper (matches 03_* mapping)\n",
    "# -----------------------------\n",
    "def run_trial(A, spike_times, tau=10*ms):\n",
    "    \"\"\"\n",
    "    Run one Brian2 trial at fixed aggregation A and return (t_ms, v_trace).\n",
    "    Mirrors your 03_* mapping:\n",
    "      Pr_effect      = 0.6 * (1 - A)\n",
    "      tau_rec_effect = 800*ms * (1 + A)\n",
    "      Synapse: v_post += Pr_effect * x ; x -= Pr_effect * x\n",
    "      dx/dt  : (1 - x) / tau_rec_effect  (clock-driven)\n",
    "    \"\"\"\n",
    "    start_scope()\n",
    "\n",
    "    # Biological mapping\n",
    "    Pr_effect      = 0.6 * (1 - A)\n",
    "    tau_rec_effect = 800*ms * (1 + A)\n",
    "\n",
    "    # Presynaptic spikes\n",
    "    source = SpikeGeneratorGroup(1, indices=[0]*len(spike_times), times=spike_times)\n",
    "\n",
    "    # Postsynaptic neuron (subthreshold LIF)\n",
    "    post = NeuronGroup(1, 'dv/dt = -v/tau : 1', method='exact')\n",
    "\n",
    "    # Synapse with short-term depression (explicit method='exact')\n",
    "    S = Synapses(\n",
    "        source, post,\n",
    "        '''\n",
    "        dx/dt = (1 - x)/tau_rec_effect : 1 (clock-driven)\n",
    "        ''',\n",
    "        on_pre='''\n",
    "        v_post += Pr_effect * x\n",
    "        x -= Pr_effect * x\n",
    "        ''',\n",
    "        method='exact'\n",
    "    )\n",
    "    S.connect()\n",
    "    S.x = 1.0\n",
    "\n",
    "    # Record voltage\n",
    "    M = StateMonitor(post, 'v', record=True)\n",
    "\n",
    "    # Simulate\n",
    "    run((max(spike_times) + 20*ms))\n",
    "\n",
    "    # Return time (ms) and voltage array\n",
    "    t_ms    = np.array(M.t/ms, dtype=float)\n",
    "    v_trace = np.array(M.v[0], dtype=float)\n",
    "    return t_ms, v_trace\n",
    "\n",
    "# -----------------------------\n",
    "# Feature engineering (robust & lightweight)\n",
    "# -----------------------------\n",
    "def compute_features(t_ms, v_trace):\n",
    "    \"\"\"\n",
    "    Features from a voltage trace:\n",
    "      - peak_v           : max(v)\n",
    "      - area_v           : integral over time (ms) via np.trapezoid\n",
    "      - t_peak           : time to peak (ms)\n",
    "      - decay_tau        : exponential decay constant (ms) after peak (log-linear fit)\n",
    "      - spectral_centroid: FFT-based frequency centroid (Hz)\n",
    "    \"\"\"\n",
    "    v0 = v_trace - np.min(v_trace)  # baseline subtract\n",
    "\n",
    "    peak_v = float(np.max(v0))\n",
    "    area_v = float(np.trapezoid(v0, t_ms))  # np.trapz → np.trapezoid\n",
    "\n",
    "    t_peak_idx = int(np.argmax(v0))\n",
    "    t_peak     = float(t_ms[t_peak_idx])\n",
    "\n",
    "    # Decay tau via log-linear fit on the tail\n",
    "    tail_mask = t_ms >= t_peak\n",
    "    t_tail = t_ms[tail_mask]\n",
    "    v_tail = v0[tail_mask]\n",
    "    eps = 1e-9\n",
    "    if len(t_tail) >= 5 and np.all(np.isfinite(v_tail)):\n",
    "        y = np.log(v_tail + eps)\n",
    "        coef = np.polyfit(t_tail - t_tail[0], y - y[0], 1)  # slope in 1/ms\n",
    "        decay_tau = float(-1.0 / coef[0]) if coef[0] < 0 else np.inf\n",
    "    else:\n",
    "        decay_tau = np.nan\n",
    "\n",
    "    # Spectral centroid\n",
    "    if len(t_ms) > 1:\n",
    "        dt_sec = (t_ms[1] - t_ms[0]) / 1000.0\n",
    "        freqs = np.fft.rfftfreq(len(t_ms), d=dt_sec)\n",
    "        Vfft = np.fft.rfft(v0)\n",
    "        P = np.abs(Vfft)**2\n",
    "        spectral_centroid = float(np.sum(freqs * P) / np.sum(P)) if np.sum(P) > 0 else 0.0\n",
    "    else:\n",
    "        spectral_centroid = 0.0\n",
    "\n",
    "    return np.array([peak_v, area_v, t_peak, decay_tau, spectral_centroid], dtype=float)\n",
    "\n",
    "feature_names = np.array(['peak_v', 'area_v', 't_peak', 'decay_tau', 'spectral_centroid'], dtype='<U32')\n",
    "\n",
    "# -----------------------------\n",
    "# Build a compact dataset (no changes to 03_*)\n",
    "# -----------------------------\n",
    "A_grid = np.linspace(0.0, 0.9, 10)  # up to 0.9 to avoid strict zeros at 1.0\n",
    "protocols = [\n",
    "    np.array([10, 20])*ms,                  # same as 03_* (two spikes)\n",
    "    np.array([10, 20, 30, 40])*ms,          # four spikes\n",
    "    np.array([10, 15, 20, 25, 30, 35])*ms,  # faster train (5 ms steps)\n",
    "    np.array([10, 50, 90])*ms               # sparse spikes\n",
    "]\n",
    "\n",
    "X_list, yA_list = [], []\n",
    "for A in A_grid:\n",
    "    for spike_times in protocols:\n",
    "        t_ms, v_trace = run_trial(A, spike_times)\n",
    "        X_list.append(compute_features(t_ms, v_trace))\n",
    "        yA_list.append(float(A))\n",
    "\n",
    "X = np.vstack(X_list).astype(float)\n",
    "y_reg = np.array(yA_list, dtype=float)\n",
    "\n",
    "print('Feature matrix:', X.shape, 'Target shape:', y_reg.shape)\n",
    "np.save('../data/features.npy', X)\n",
    "np.save('../data/labels_regression.npy', y_reg)\n",
    "np.save('../data/feature_names.npy', feature_names)\n",
    "print('Saved features/labels to ../data/')\n",
    "\n",
    "# -----------------------------\n",
    "# Classification target (bins)\n",
    "# -----------------------------\n",
    "y_cls = np.digitize(y_reg, bins=[0.33, 0.66])  # 0=low, 1=medium, 2=high\n",
    "classes, counts = np.unique(y_cls, return_counts=True)\n",
    "print('Class distribution:', {int(c): int(n) for c, n in zip(classes, counts)})\n",
    "\n",
    "# -----------------------------\n",
    "# Train/test splits\n",
    "# -----------------------------\n",
    "X_train, X_test, yreg_train, yreg_test = train_test_split(\n",
    "    X, y_reg, test_size=0.25, random_state=42\n",
    ")\n",
    "Xc_train, Xc_test, ycls_train, ycls_test = train_test_split(\n",
    "    X, y_cls, test_size=0.25, random_state=42, stratify=y_cls\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Regressor: predict aggregation index (A)\n",
    "# -----------------------------\n",
    "reg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(n_estimators=400, random_state=42))\n",
    "])\n",
    "reg.fit(X_train, yreg_train)\n",
    "ypred = reg.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(yreg_test, ypred)\n",
    "r2  = r2_score(yreg_test, ypred)\n",
    "print(f'[Regression] MAE={mae:.4f}, R^2={r2:.4f}')\n",
    "\n",
    "# Permutation importance (ASCII +/- to avoid unicode issues)\n",
    "imp = permutation_importance(reg, X_test, yreg_test, n_repeats=10, random_state=42)\n",
    "order = np.argsort(-imp.importances_mean)\n",
    "print(\"\\n[Regression] Feature importances (permutation):\")\n",
    "for idx in order:\n",
    "    mean = float(imp.importances_mean[idx])\n",
    "    std  = float(imp.importances_std[idx])\n",
    "    name = str(feature_names[idx])\n",
    "    print(f\"  {name}: {mean:.4f} +/- {std:.4f}\")\n",
    "\n",
    "joblib.dump(reg, '../models/agg_index_regressor.joblib')\n",
    "print('Saved regressor → ../models/agg_index_regressor.joblib')\n",
    "\n",
    "# -----------------------------\n",
    "# Classifier: severity (low/medium/high)\n",
    "# -----------------------------\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=42))\n",
    "])\n",
    "clf.fit(Xc_train, ycls_train)\n",
    "ycls_pred = clf.predict(Xc_test)\n",
    "\n",
    "print('\\n[Classification] Report:')\n",
    "print(classification_report(ycls_test, ycls_pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(ycls_test, ycls_pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title('Confusion Matrix (low/medium/high)')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.xticks([0,1,2], ['low','med','high']); plt.yticks([0,1,2], ['low','med','high'])\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/05_cls_confusion.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "joblib.dump(clf, '../models/agg_severity_classifier.joblib')\n",
    "print('Saved classifier → ../models/agg_severity_classifier.joblib')\n",
    "\n",
    "# -----------------------------\n",
    "# Inference helper (single trace)\n",
    "# -----------------------------\n",
    "def predict_from_trace(t_ms, v_trace):\n",
    "    feats = compute_features(t_ms, v_trace).reshape(1, -1)\n",
    "    A_hat = reg.predict(feats)[0]\n",
    "    cls_hat = clf.predict(feats)[0]\n",
    "    cls_name = {0:'low', 1:'medium', 2:'high'}[int(cls_hat)]\n",
    "    return float(A_hat), cls_name, feats.flatten()\n",
    "\n",
    "# Quick demo\n",
    "t_ms_demo, v_demo_trace = run_trial(A=0.55, spike_times=np.array([10,20,30,40])*ms)\n",
    "A_hat, cls_name, feats = predict_from_trace(t_ms_demo, v_demo_trace)\n",
    "print(f'\\n[Inference demo] True A=0.55 → Predicted A={A_hat:.2f}, class={cls_name}')\n",
    "print('Features:', dict(zip(feature_names.tolist(), feats)))\n",
    "\n",
    "plt.figure(figsize=(6,3.5))\n",
    "plt.plot(t_ms_demo, v_demo_trace)\n",
    "plt.title('Demo voltage trace (A=0.55)')\n",
    "plt.xlabel('Time (ms)'); plt.ylabel('v(t)'); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/05_inference_demo.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Scope note\n",
    "# -----------------------------\n",
    "# The ML here recognizes signal degradation patterns at a single synapse in this model.\n",
    "# It does not identify or diagnose diseases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167abdb5-83c7-4259-afdc-70ef6cc5df9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
